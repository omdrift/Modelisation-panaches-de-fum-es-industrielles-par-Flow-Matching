# VQVAE configuration optimisée pour GPU puissant
name: "vqvae_smoke_pro"

# Configuration de l'encodeur : Augmentation des canaux pour plus de détails
encoder:
  in_channels: 3
  out_channels: 256 # Aligné avec l'embedding_dimension pour l'espace latent
  mid_channels: 128 # Augmenté de 32 à 128 pour capturer plus de textures

# Configuration du décodeur
decoder:
  in_channels: 256
  out_channels: 3
  mid_channels: 128

# Bottleneck de quantification vectorielle
vector_quantizer:
  embedding_dimension: 256
  num_embeddings: 1024  # Dictionnaire riche pour éviter la généralisation au noir
  commitment_cost: 0.1  # Réduit pour une meilleure flexibilité du codebook

# Paramètres de données
data:
  data_root: "final_dataset/"
  input_size: 64
  crop_size: 64
  random_horizontal_flip: True

# Hyperparamètres d'entraînement optimisés
training:
  batch_size: 64        # Augmenté pour la stabilité sur gros GPU
  learning_rate: 2e-4   # Ajusté pour la nouvelle capacité
  weight_decay: 1e-6    #
  epochs: 100
# Minimal model & evaluation entries required by project
model:
  reference: True

evaluation:
  past_horizon: -1
  warm_sampling: 0.0
  steps: 100

notes:
  - "This config is aligned with train_vqvae.py and smoke_dataset.yaml"
  - "Input/output: 64x64 images -> 8x8 latent space (state_res in smoke_dataset.yaml)"
  - "Latent channels: 4 (state_size in smoke_dataset.yaml)"
